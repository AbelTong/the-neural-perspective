import tensorflow as tfimport numpy as npclass parameters():	def __init__(self):		self.DATA_LENGTH = 10000		self.LEARNING_RATE = 1e-10		self.REG = 1e-10		self.NUM_EPOCHS =  2000		self.BATCH_SIZE = 64		self.DISPLAY_STEP = 100 # epochdef generate_data(data_length):	"""	Load the data.	"""	X = np.array(range(data_length))	y = 3.657*X + np.random.randn(*X.shape) * 0.33	return X, ydef generate_batches(data_length, batch_size):	"""	Create <num_batches> batches from X and y	"""	X, y = generate_data(data_length)	# Create batches	num_batches = data_length // batch_size	data_X = np.zeros([num_batches, batch_size], dtype=np.float32)	data_y = np.zeros([num_batches, batch_size], dtype=np.float32)	for batch_num in range(num_batches):		data_X[batch_num,:] = X[batch_num*batch_size:(batch_num+1)*batch_size]		data_y[batch_num,:] = y[batch_num*batch_size:(batch_num+1)*batch_size]	yield data_X.reshape(-1, 1), data_y.reshape(-1, 1)def generate_epochs(num_epochs, data_length, batch_size):	"""	Create batches for <num_epochs> epochs. 	"""	for epoch_num in range(num_epochs):		yield generate_batches(data_length, batch_size)class model(object):	"""	Train the linear model to minimize L2 loss function.	"""	def __init__(self, learning_rate, reg):		# Inputs		self.X = tf.placeholder(tf.float32, [None, 1], "X")		self.y = tf.placeholder(tf.float32, [None, 1], "y")		# Set model weights		with tf.variable_scope('weights'):			self.W = tf.Variable(tf.truncated_normal([1,1], stddev=0.01), name="W", dtype=tf.float32)			self.b = tf.Variable(tf.truncated_normal([1,1], stddev=0.01), name="b", dtype=tf.float32)		# Forward pass		self.prediction = tf.add(tf.matmul(self.X, self.W), self.b)		# L2 loss		self.cost = tf.reduce_mean(tf.pow(self.prediction-self.y, 2)) + reg * tf.reduce_sum(self.W * self.W)		# Gradient descent (backprop)		self.optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(self.cost)	def step(self, sess, batch_X, batch_y):		input_feed = {self.X:batch_X, self.y:batch_y}		output_feed = [self.prediction,					self.cost,					self.optimizer,					self.W,					self.b]		outputs = sess.run(output_feed, input_feed)		return outputs[0], outputs[1], outputs[2], outputs[3], outputs[4] # prediction, cost, optimizer, W, bdef create_model(sess, FLAGS):	linear_model = model(FLAGS.LEARNING_RATE, FLAGS.REG)	sess.run(tf.initialize_all_variables())	return linear_modeldef train(FLAGS):	with tf.Session() as sess:		# Create the model		model = create_model(sess, FLAGS)		for epoch_num, epoch in enumerate(generate_epochs(FLAGS.NUM_EPOCHS, FLAGS.DATA_LENGTH, FLAGS.BATCH_SIZE)):			for simult_batch_num, (input_X, labels_y) in enumerate(epoch):				prediction, training_loss, _, W, b = model.step(sess, input_X, labels_y)			# Display			if epoch_num%FLAGS.DISPLAY_STEP == 0:				print "EPOCH %i: \n Training loss: %.3f, W: %.3f, b:%.3f" % (					epoch_num, training_loss, W, b)if __name__ == '__main__':		FLAGS = parameters()	train(FLAGS)